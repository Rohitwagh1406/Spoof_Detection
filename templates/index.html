<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebCam Access</title>
    <style>
        video, img {
            max-width: 100%;
            height: auto;
        }
    </style>
</head>
<body>
    <h1>WebCam Feed</h1>
    <video id="video" autoplay></video>
    <img id="snapshot" alt="Captured Frame">
    <script>
        // Access the webcam
        const video = document.getElementById('video');
        const snapshot = document.getElementById('snapshot');
        
        async function init() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                await startSendingFrames();
            } catch (err) {
                console.error("Error accessing webcam or starting frame sending: ", err);
            }
        }

        // Function to send frames to the backend
        async function startSendingFrames() {
            const canvas = document.createElement('canvas');
            const context = canvas.getContext('2d');

            function captureFrame() {
                return new Promise((resolve, reject) => {
                    if (video.paused || video.ended) {
                        reject('Video stream paused or ended');
                    }

                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    context.drawImage(video, 0, 0, canvas.width, canvas.height);

                    canvas.toBlob(blob => {
                        if (!blob) {
                            reject('Failed to capture frame as blob');
                        }
                        resolve(blob);
                    }, 'image/jpeg');
                });
            }

            async function sendFrame() {
                try {
                    const blob = await captureFrame();
                    const formData = new FormData();
                    formData.append('frame', blob, 'frame.jpg');

                    const response = await fetch('/video_feed', {
                        method: 'POST',
                        body: formData
                    });

                    if (!response.ok) {
                        throw new Error('Failed to receive image from server');
                    }

                    const processedBlob = await response.blob();
                    const url = URL.createObjectURL(processedBlob);
                    snapshot.src = url;
                } catch (err) {
                    console.error('Error sending or receiving frame:', err);
                } finally {
                    setTimeout(sendFrame, 100); // Capture a frame every 100ms
                }
            }

            await sendFrame(); // Start sending frames
        }

        // Initialize the application
        init().catch(err => console.error('Error initializing application:', err));
    </script>
</body>
</html>





<!-- <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebCam Access</title>
    <style>
        video, img {
            max-width: 100%;
            height: auto;
        }
    </style>
</head>
<body>
    <h1>WebCam Feed</h1>
    <video id="video" autoplay></video>
    <img id="snapshot" alt="Captured Frame">
    <script>
        // Access the webcam
        const video = document.getElementById('video');
        const snapshot = document.getElementById('snapshot');
        
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(stream => {
                video.srcObject = stream;
            })
            .catch(err => {
                console.error("Error accessing webcam: ", err);
            });

        // Capture the frame from the video feed and send it to the backend
        video.addEventListener('play', () => {
            const canvas = document.createElement('canvas');
            const context = canvas.getContext('2d');

            function sendFrame() {
                if (video.paused || video.ended) {
                    return;
                }

                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                context.drawImage(video, 0, 0, canvas.width, canvas.height);

                canvas.toBlob(blob => {
                    const formData = new FormData();
                    formData.append('frame', blob, 'frame.jpg');

                    fetch('/video_feed', {
                        method: 'POST',
                        body: formData
                    })
                    .then(response => response.blob())
                    .then(blob => {
                        const url = URL.createObjectURL(blob);
                        snapshot.src = url;
                    })
                    .catch(err => console.error('Error sending frame:', err));
                }, 'image/jpeg');

                setTimeout(sendFrame, 100); // Capture a frame every 100ms
            }

            sendFrame();
        });
    </script>
</body>
</html> -->
